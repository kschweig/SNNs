{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial on self-normalizing networks on the CIFAR-10 data set\n",
    "\n",
    "Adapted from CIFAR10 tutorial from [exelban](https://github.com/exelban/tensorflow-cifar-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kai/miniconda3/envs/snn/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/kai/miniconda3/envs/snn/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/kai/miniconda3/envs/snn/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/kai/miniconda3/envs/snn/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/kai/miniconda3/envs/snn/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/kai/miniconda3/envs/snn/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/kai/miniconda3/envs/snn/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/kai/miniconda3/envs/snn/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/kai/miniconda3/envs/snn/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/kai/miniconda3/envs/snn/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/kai/miniconda3/envs/snn/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/kai/miniconda3/envs/snn/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "\n",
    "import pickle\n",
    "import sys\n",
    "import tarfile\n",
    "import zipfile\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Fetch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data_set(name=\"train\", cifar=10):\n",
    "    x = None\n",
    "    y = None\n",
    "    l = None\n",
    "    \n",
    "    maybe_download_and_extract()\n",
    "    \n",
    "    folder_name = \"cifar_10\" if cifar == 10 else \"cifar_100\"\n",
    "    \n",
    "    f = open('./data_set/' + folder_name + '/batches.meta', 'rb')\n",
    "    datadict = pickle.load(f, encoding='latin1')\n",
    "    f.close()\n",
    "    l = datadict['label_names']\n",
    "    \n",
    "    # mean and sdev of training set\n",
    "    mean_train = 0.4733630004850902\n",
    "    sdev_train = 0.2515689250632212\n",
    "    \n",
    "    if name is \"train\":\n",
    "        for i in range(5):\n",
    "            f = open('./data_set/' + folder_name + '/data_batch_' + str(i + 1), 'rb')\n",
    "            datadict = pickle.load(f, encoding='latin1')\n",
    "            f.close()\n",
    "            \n",
    "            _X = datadict[\"data\"]\n",
    "            _Y = datadict['labels']\n",
    "            \n",
    "            _X = np.array(_X, dtype=float) / 255.0\n",
    "            _X = _X.reshape([-1, 3, 32, 32])\n",
    "            _X = _X.transpose([0, 2, 3, 1])\n",
    "            _X = _X.reshape(-1, 32 * 32 * 3)\n",
    "            \n",
    "            if x is None:\n",
    "                x = _X\n",
    "                y = _Y\n",
    "            else:\n",
    "                x = np.concatenate((x, _X), axis=0)\n",
    "                y = np.concatenate((y, _Y), axis=0)\n",
    "        \n",
    "        # Normalize Data to mean = 0, stdev = 1\n",
    "        x = (x - mean_train) / sdev_train\n",
    "    \n",
    "    elif name is \"test\":\n",
    "        f = open('./data_set/' + folder_name + '/test_batch', 'rb')\n",
    "        datadict = pickle.load(f, encoding='latin1')\n",
    "        f.close()\n",
    "        \n",
    "        x = datadict[\"data\"]\n",
    "        y = np.array(datadict['labels'])\n",
    "        \n",
    "        x = np.array(x, dtype=float) / 255.0\n",
    "        x = x.reshape([-1, 3, 32, 32])\n",
    "        x = x.transpose([0, 2, 3, 1])\n",
    "        x = x.reshape(-1, 32 * 32 * 3)\n",
    "        \n",
    "        # Normalize Data according to mean and sdev of training set\n",
    "        x = (x - mean_train) / sdev_train\n",
    "    \n",
    "    def dense_to_one_hot(labels_dense, num_classes=10):\n",
    "        num_labels = labels_dense.shape[0]\n",
    "        index_offset = np.arange(num_labels) * num_classes\n",
    "        labels_one_hot = np.zeros((num_labels, num_classes))\n",
    "        labels_one_hot.flat[index_offset + labels_dense.ravel()] = 1\n",
    "        \n",
    "        return labels_one_hot\n",
    "    \n",
    "    return x, dense_to_one_hot(y), l\n",
    "\n",
    "\n",
    "def _print_download_progress(count, block_size, total_size):\n",
    "    pct_complete = float(count * block_size) / total_size\n",
    "    msg = \"\\r- Download progress: {0:.1%}\".format(pct_complete)\n",
    "    sys.stdout.write(msg)\n",
    "    sys.stdout.flush()\n",
    "\n",
    "\n",
    "def maybe_download_and_extract():\n",
    "    main_directory = \"./data_set/\"\n",
    "    cifar_10_directory = main_directory + \"cifar_10/\"\n",
    "    cifar_100_directory = main_directory + \"cifar_100/\"\n",
    "    if not os.path.exists(main_directory):\n",
    "        os.makedirs(main_directory)\n",
    "        \n",
    "        url = \"http://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\"\n",
    "        filename = url.split('/')[-1]\n",
    "        file_path = os.path.join(main_directory, filename)\n",
    "        zip_cifar_10 = file_path\n",
    "        file_path, _ = urlretrieve(url=url, filename=file_path, reporthook=_print_download_progress)\n",
    "        \n",
    "        print()\n",
    "        print(\"Download finished. Extracting files.\")\n",
    "        if file_path.endswith(\".zip\"):\n",
    "            zipfile.ZipFile(file=file_path, mode=\"r\").extractall(main_directory)\n",
    "        elif file_path.endswith((\".tar.gz\", \".tgz\")):\n",
    "            tarfile.open(name=file_path, mode=\"r:gz\").extractall(main_directory)\n",
    "        print(\"Done.\")\n",
    "        \n",
    "        url = \"http://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\"\n",
    "        filename = url.split('/')[-1]\n",
    "        file_path = os.path.join(main_directory, filename)\n",
    "        zip_cifar_100 = file_path\n",
    "        file_path, _ = urlretrieve(url=url, filename=file_path, reporthook=_print_download_progress)\n",
    "        \n",
    "        print()\n",
    "        print(\"Download finished. Extracting files.\")\n",
    "        if file_path.endswith(\".zip\"):\n",
    "            zipfile.ZipFile(file=file_path, mode=\"r\").extractall(main_directory)\n",
    "        elif file_path.endswith((\".tar.gz\", \".tgz\")):\n",
    "            tarfile.open(name=file_path, mode=\"r:gz\").extractall(main_directory)\n",
    "        print(\"Done.\")\n",
    "        \n",
    "        os.rename(main_directory + \"./cifar-10-batches-py\", cifar_10_directory)\n",
    "        os.rename(main_directory + \"./cifar-100-python\", cifar_100_directory)\n",
    "        os.remove(zip_cifar_10)\n",
    "        os.remove(zip_cifar_100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaled ELU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def selu(x, name=\"selu\"):\n",
    "    \"\"\" When using SELUs you have to keep the following in mind:\n",
    "    # (1) scale inputs to zero mean and unit variance\n",
    "    # (2) use SELUs\n",
    "    # (3) initialize weights with stddev sqrt(1/n)\n",
    "    # (4) use SELU dropout\n",
    "    \"\"\"\n",
    "    with ops.name_scope(name) as scope:\n",
    "        alpha = 1.6732632423543772848170429916717\n",
    "        scale = 1.0507009873554804934193349852946\n",
    "        return scale * tf.where(x >= 0.0, x, alpha * tf.nn.elu(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some helpers to build the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _variable_with_weight_decay(name, shape, activation, stddev, wd=None):    \n",
    "    # Determine number of input features from shape\n",
    "    f_in = np.prod(shape[:-1]) if len(shape) == 4 else shape[0]\n",
    "    \n",
    "    # Calculate sdev for initialization according to activation function\n",
    "    if activation == selu:\n",
    "        sdev = sqrt(1 / f_in)\n",
    "    elif activation == tf.nn.relu:\n",
    "        sdev = sqrt(2 / f_in)\n",
    "    elif activation == tf.nn.elu:\n",
    "        sdev = sqrt(1.5505188080679277 / f_in)\n",
    "    else:\n",
    "        sdev = stddev\n",
    "    \n",
    "    var = tf.get_variable(name=name, shape=shape,\n",
    "                          initializer=tf.truncated_normal_initializer(stddev=sdev, dtype=tf.float32))\n",
    "    if wd is not None:\n",
    "        weight_decay = tf.multiply(tf.nn.l2_loss(var), wd, name='weight_loss')\n",
    "        tf.add_to_collection('losses', weight_decay)\n",
    "    return var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d(scope_name, input, activation, ksize, f_in, f_out, bias_init=0.0, stddev=5e-2):\n",
    "    with tf.variable_scope(scope_name) as scope:\n",
    "        kernel = _variable_with_weight_decay('weights', shape=[ksize, ksize, f_in, f_out], activation=activation,\n",
    "                                             stddev=stddev)\n",
    "        conv = tf.nn.conv2d(input, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "        biases = tf.get_variable('biases', [f_out], initializer=tf.constant_initializer(bias_init), dtype=tf.float32)\n",
    "        pre_activation = tf.nn.bias_add(conv, biases)\n",
    "        return activation(pre_activation, name=scope.name)\n",
    "\n",
    "\n",
    "def fc(scope_name, input, activation, n_in, n_out, stddev=0.04, bias_init=0.0, weight_decay=None):\n",
    "    with tf.variable_scope(scope_name) as scope:\n",
    "        weights = _variable_with_weight_decay('weights', shape=[n_in, n_out], activation=activation, stddev=stddev,\n",
    "                                              wd=weight_decay)\n",
    "        biases = tf.get_variable(name='biases', shape=[n_out], initializer=tf.constant_initializer(bias_init),\n",
    "                                 dtype=tf.float32)\n",
    "        return activation(tf.matmul(input, weights) + biases, name=scope.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model with a specified activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model(activation):\n",
    "    _IMAGE_SIZE = 32\n",
    "    _IMAGE_CHANNELS = 3\n",
    "    _NUM_CLASSES = 10\n",
    "    _RESHAPE_SIZE = 4 * 4 * 128\n",
    "    \n",
    "    # set activation function\n",
    "    act = selu if activation == \"selu\" else tf.nn.elu if activation == \"elu\" else tf.nn.relu\n",
    "    \n",
    "    with tf.variable_scope(activation):\n",
    "        # input\n",
    "        with tf.name_scope('data'):\n",
    "            x = tf.placeholder(tf.float32, shape=[None, _IMAGE_SIZE * _IMAGE_SIZE * _IMAGE_CHANNELS], name='Input')\n",
    "            y = tf.placeholder(tf.float32, shape=[None, _NUM_CLASSES], name='Output')\n",
    "            x_image = tf.reshape(x, [-1, _IMAGE_SIZE, _IMAGE_SIZE, _IMAGE_CHANNELS], name='images')\n",
    "        \n",
    "        # Conv 1\n",
    "        conv1 = conv2d(\"conv1\", input=x_image, activation=act, ksize=5, f_in=3, f_out=64)\n",
    "        pool1 = tf.nn.max_pool(conv1, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], padding='SAME', name='pool1')\n",
    "        \n",
    "        # Conv 2\n",
    "        conv2 = conv2d(\"conv2\", input=pool1, activation=act, ksize=5, f_in=64, f_out=64, bias_init=0.1)\n",
    "        pool2 = tf.nn.max_pool(conv2, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], padding='SAME', name='pool2')\n",
    "        \n",
    "        # Conv 3-5\n",
    "        conv3 = conv2d(\"conv3\", input=pool2, activation=act, ksize=3, f_in=64, f_out=128)\n",
    "        conv4 = conv2d(\"conv4\", input=conv3, activation=act, ksize=3, f_in=128, f_out=128)\n",
    "        conv5 = conv2d(\"conv5\", input=conv4, activation=act, ksize=3, f_in=128, f_out=128)\n",
    "        \n",
    "        # Pool\n",
    "        pool3 = tf.nn.max_pool(conv5, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], padding='SAME', name='pool3')\n",
    "        \n",
    "        # Reshape\n",
    "        reshape = tf.reshape(pool3, [-1, _RESHAPE_SIZE])\n",
    "        dim = reshape.get_shape()[1].value\n",
    "        \n",
    "        # Fully Connected\n",
    "        fc1 = fc('fully_connected1', input=reshape, activation=act, n_in=dim, n_out=384, stddev=0.04, bias_init=0.1,\n",
    "                 weight_decay=0.004)\n",
    "        fc2 = fc('fully_connected2', input=fc1, activation=act, n_in=384, n_out=192, stddev=0.04, bias_init=0.1,\n",
    "                 weight_decay=0.004)\n",
    "        \n",
    "        # Softmax\n",
    "        with tf.variable_scope('output') as scope:\n",
    "            weights = _variable_with_weight_decay('weights', [192, _NUM_CLASSES], stddev=1 / 192.0,\n",
    "                                                  activation=activation,\n",
    "                                                  wd=0.0)\n",
    "            biases = tf.get_variable(name='biases', shape=[_NUM_CLASSES], initializer=tf.constant_initializer(0.0),\n",
    "                                     dtype=tf.float32)\n",
    "            softmax_linear = tf.add(tf.matmul(fc2, weights), biases, name=scope.name)\n",
    "            \n",
    "            # output\n",
    "            y_pred_cls = tf.argmax(softmax_linear, dimension=1)\n",
    "        \n",
    "        # Define Loss and Optimizer\n",
    "        loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=softmax_linear, labels=y))\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(loss)\n",
    "        \n",
    "        correct_prediction = tf.equal(y_pred_cls, tf.argmax(y, dimension=1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "        # tf.summary.scalar(\"Accuracy/train\", accuracy)\n",
    "    \n",
    "    return {\"x\": x, \"y\": y, \"output\": y_pred_cls, \"loss\": loss, \"accuracy\": accuracy, \"optimizer\": optimizer, \"name\": activation}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_test(test_x, test_y, models):\n",
    "    \"\"\"\n",
    "        Make prediction for all images in test_x\n",
    "    \"\"\"\n",
    "    i = 0\n",
    "    predicted_class = {\"selu\": np.zeros(shape=len(test_x), dtype=np.int32),\n",
    "                       \"elu\": np.zeros(shape=len(test_x), dtype=np.int32),\n",
    "                       \"relu\":np.zeros(shape=len(test_x), dtype=np.int32)}\n",
    "    while i < len(test_x):\n",
    "        j = min(i + _BATCH_SIZE, len(test_x))\n",
    "        batch_xs = test_x[i:j, :]\n",
    "        batch_ys = test_y[i:j, :]\n",
    "        for name, model in models.items():\n",
    "            predicted_class[name][i:j] = sess.run(model[\"output\"], feed_dict={model['x']: batch_xs, model['y']: batch_ys})\n",
    "        i = j\n",
    "    \n",
    "    accuracy = {\"selu\": 0, \"elu\": 0, \"relu\": 0}\n",
    "    for name, model in models.items():\n",
    "        correct = (np.argmax(test_y, axis=1) == predicted_class[name])        \n",
    "        accuracy[name] = correct.mean() * 100        \n",
    "    \n",
    "    print(\"Accuracy on Test-Set (SELU/ELU/RELU): {0:.2f}% | {1:.2f}% | {2:.2f}%\".format(\n",
    "        accuracy[\"selu\"], accuracy[\"elu\"], accuracy[\"relu\"]))\n",
    "    \n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_metric(title, ylabel, metric):\n",
    "    # Training Accuracy\n",
    "    plt.figure()    \n",
    "    plt.title(title, size=\"xx-large\")\n",
    "    plt.ylabel(ylabel, size=\"x-large\")    \n",
    "    plt.tick_params(axis=\"x\", bottom=\"off\", labelbottom=\"off\")\n",
    "    \n",
    "    # select manually for consistent colors\n",
    "    plt.plot(metric[\"selu\"], label=\"SELU\", linewidth=2)\n",
    "    plt.plot(metric[\"elu\"], label=\"ELU\", linewidth=2)\n",
    "    plt.plot(metric[\"relu\"], label=\"RELU\", linewidth=2)\n",
    "        \n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def plot(train_loss, train_accuracy, test_accuracy):    \n",
    "    # Training Loss\n",
    "    plot_metric(\"Training Loss\", \"Loss\", train_loss)\n",
    "    \n",
    "    # Training Accuracy\n",
    "    plot_metric(\"Training Accuracy\", \"Accuracy\", train_accuracy)\n",
    "    \n",
    "    # Test Accuracy\n",
    "    plot_metric(\"Test Accuracy\", \"Accuracy\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(session, num_iterations, train_x, train_y, test_x, test_y, models, global_step):\n",
    "    \"\"\"\n",
    "        Train CNN\n",
    "    \"\"\"    \n",
    "    train_loss = {\"selu\": [], \"elu\":[], \"relu\": []}\n",
    "    train_accuracy = {\"selu\": [], \"elu\":[], \"relu\": []}    \n",
    "    test_accuracy = {\"selu\": [], \"elu\":[], \"relu\": []}\n",
    "    \n",
    "    inc_step_op = tf.assign(global_step, global_step+1)\n",
    "    # start training\n",
    "    for i in range(num_iterations):\n",
    "        randidx = np.random.randint(len(train_x), size=_BATCH_SIZE)\n",
    "        batch_xs = train_x[randidx]\n",
    "        batch_ys = train_y[randidx]\n",
    "                \n",
    "        optimizers = []\n",
    "        feed_dict = {}\n",
    "        for name, model in models.items():\n",
    "            optimizers.append(model[\"optimizer\"])\n",
    "            feed_dict.update({model[\"x\"]: batch_xs, model[\"y\"]: batch_ys})\n",
    "        \n",
    "        # current step\n",
    "        i_global = session.run(global_step)\n",
    "        \n",
    "        # train\n",
    "        session.run( optimizers, feed_dict=feed_dict)\n",
    "        \n",
    "        # print training loss\n",
    "        if (i_global % 10 == 0) or (i == num_iterations - 1):\n",
    "            l_selu, l_elu, l_relu, acc_selu, acc_elu, acc_relu = session.run(\n",
    "                [models['selu']['loss'], models['elu']['loss'], models['relu']['loss'], \n",
    "                 models['selu']['accuracy'], models['elu']['accuracy'], models['relu']['accuracy']],\n",
    "                feed_dict=feed_dict)\n",
    "            \n",
    "            msg = \"Global Step: {0:>6}, \" \\\n",
    "                  \"accuracy (SELU/ELU/RELU): {1:>6.1%} | {2:>6.1%} | {3:>6.1%}, \" \\\n",
    "                  \"loss (SELU/ELU/RELU): {4:.2f} | {5:.2f} | {6:.2f}\"\n",
    "            print(msg.format(i_global, acc_selu, acc_elu, acc_relu, l_selu, l_elu, l_relu))            \n",
    "            \n",
    "            # collect metrics for plots                            \n",
    "            train_loss[\"selu\"].append(l_selu)\n",
    "            train_loss[\"elu\"].append(l_elu)\n",
    "            train_loss[\"relu\"].append(l_relu)\n",
    "            train_accuracy[\"selu\"].append(acc_selu)\n",
    "            train_accuracy[\"elu\"].append(acc_elu)\n",
    "            train_accuracy[\"relu\"].append(acc_relu)\n",
    "\n",
    "        # evaluate test set accuracy\n",
    "        if (i_global % 100 == 0) or (i == num_iterations - 1):\n",
    "            acc = predict_test(test_x, test_y, models)                \n",
    "            test_accuracy[\"selu\"].append(acc[\"selu\"])\n",
    "            test_accuracy[\"elu\"].append(acc[\"elu\"])\n",
    "            test_accuracy[\"relu\"].append(acc[\"relu\"])\n",
    "            saver.save(session, save_path=_SAVE_PATH + \"/checkpoint\", global_step=global_step)\n",
    "            print(\"Saved checkpoint.\")\n",
    "        \n",
    "        # increment global step\n",
    "        session.run(inc_step_op)\n",
    "    return train_loss, train_accuracy, test_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_IMG_SIZE = 32\n",
    "_NUM_CHANNELS = 3\n",
    "_BATCH_SIZE = 128\n",
    "_CLASS_SIZE = 10\n",
    "_ITERATION = 10000\n",
    "_SAVE_PATH = \"./checkpoints/cifar-10\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set GPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "if not os.path.exists(_SAVE_PATH):\n",
    "    os.makedirs(_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-4-18ff1be5653d>:16: calling TruncatedNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From <ipython-input-6-08c2b124511b>:53: calling argmax (from tensorflow.python.ops.math_ops) with dimension is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the `axis` argument instead\n",
      "WARNING:tensorflow:From <ipython-input-6-08c2b124511b>:56: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "WARNING:tensorflow:From <ipython-input-3-687a2dd06014>:11: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "# Build Graph\n",
    "relu = model(\"relu\")\n",
    "selu = model(\"selu\")\n",
    "elu = model(\"elu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to restore last checkpoint ...\n",
      "WARNING:tensorflow:From /home/kai/miniconda3/envs/snn/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoints/cifar-10/checkpoint-500\n",
      "Restored checkpoint from: ./checkpoints/cifar-10/checkpoint-500\n",
      "Global Step:    500, accuracy (SELU/ELU/RELU):  58.6% |  59.4% |  57.8%, loss (SELU/ELU/RELU): 1.11 | 1.20 | 1.31\n",
      "Accuracy on Test-Set (SELU/ELU/RELU): 56.98% | 54.57% | 50.11%\n",
      "Saved checkpoint.\n",
      "Global Step:    510, accuracy (SELU/ELU/RELU):  61.7% |  57.0% |  55.5%, loss (SELU/ELU/RELU): 1.01 | 1.17 | 1.25\n",
      "Global Step:    520, accuracy (SELU/ELU/RELU):  64.1% |  54.7% |  47.7%, loss (SELU/ELU/RELU): 1.04 | 1.22 | 1.32\n",
      "Global Step:    530, accuracy (SELU/ELU/RELU):  57.8% |  57.8% |  51.6%, loss (SELU/ELU/RELU): 1.10 | 1.15 | 1.24\n",
      "Global Step:    540, accuracy (SELU/ELU/RELU):  68.0% |  66.4% |  55.5%, loss (SELU/ELU/RELU): 1.06 | 1.17 | 1.22\n",
      "Global Step:    550, accuracy (SELU/ELU/RELU):  55.5% |  50.8% |  48.4%, loss (SELU/ELU/RELU): 1.24 | 1.31 | 1.42\n",
      "Global Step:    560, accuracy (SELU/ELU/RELU):  56.2% |  46.1% |  45.3%, loss (SELU/ELU/RELU): 1.22 | 1.34 | 1.47\n",
      "Global Step:    570, accuracy (SELU/ELU/RELU):  55.5% |  57.8% |  46.9%, loss (SELU/ELU/RELU): 1.07 | 1.14 | 1.27\n",
      "Global Step:    580, accuracy (SELU/ELU/RELU):  59.4% |  52.3% |  51.6%, loss (SELU/ELU/RELU): 1.19 | 1.26 | 1.32\n",
      "Global Step:    590, accuracy (SELU/ELU/RELU):  60.2% |  53.9% |  52.3%, loss (SELU/ELU/RELU): 1.19 | 1.29 | 1.34\n",
      "Global Step:    600, accuracy (SELU/ELU/RELU):  57.8% |  54.7% |  49.2%, loss (SELU/ELU/RELU): 1.18 | 1.26 | 1.34\n",
      "Accuracy on Test-Set (SELU/ELU/RELU): 59.61% | 57.12% | 52.91%\n",
      "Saved checkpoint.\n",
      "Global Step:    610, accuracy (SELU/ELU/RELU):  62.5% |  59.4% |  52.3%, loss (SELU/ELU/RELU): 1.07 | 1.13 | 1.23\n",
      "Global Step:    620, accuracy (SELU/ELU/RELU):  63.3% |  57.8% |  52.3%, loss (SELU/ELU/RELU): 1.04 | 1.15 | 1.25\n",
      "Global Step:    630, accuracy (SELU/ELU/RELU):  53.9% |  46.9% |  42.2%, loss (SELU/ELU/RELU): 1.25 | 1.34 | 1.43\n",
      "Global Step:    640, accuracy (SELU/ELU/RELU):  59.4% |  53.1% |  55.5%, loss (SELU/ELU/RELU): 1.12 | 1.20 | 1.26\n",
      "Global Step:    650, accuracy (SELU/ELU/RELU):  60.9% |  60.9% |  59.4%, loss (SELU/ELU/RELU): 1.02 | 1.09 | 1.23\n",
      "Global Step:    660, accuracy (SELU/ELU/RELU):  58.6% |  57.0% |  57.0%, loss (SELU/ELU/RELU): 1.13 | 1.21 | 1.31\n",
      "Global Step:    670, accuracy (SELU/ELU/RELU):  65.6% |  64.8% |  59.4%, loss (SELU/ELU/RELU): 0.95 | 1.05 | 1.12\n",
      "Global Step:    680, accuracy (SELU/ELU/RELU):  60.2% |  58.6% |  51.6%, loss (SELU/ELU/RELU): 1.02 | 1.11 | 1.30\n",
      "Global Step:    690, accuracy (SELU/ELU/RELU):  65.6% |  61.7% |  55.5%, loss (SELU/ELU/RELU): 0.99 | 1.04 | 1.18\n",
      "Global Step:    700, accuracy (SELU/ELU/RELU):  54.7% |  51.6% |  47.7%, loss (SELU/ELU/RELU): 1.21 | 1.35 | 1.43\n",
      "Accuracy on Test-Set (SELU/ELU/RELU): 60.59% | 57.91% | 53.09%\n",
      "Saved checkpoint.\n",
      "Global Step:    710, accuracy (SELU/ELU/RELU):  61.7% |  60.2% |  57.0%, loss (SELU/ELU/RELU): 1.11 | 1.11 | 1.22\n",
      "Global Step:    720, accuracy (SELU/ELU/RELU):  61.7% |  62.5% |  53.9%, loss (SELU/ELU/RELU): 0.99 | 1.05 | 1.25\n",
      "Global Step:    730, accuracy (SELU/ELU/RELU):  56.2% |  50.0% |  50.8%, loss (SELU/ELU/RELU): 1.24 | 1.30 | 1.32\n",
      "Global Step:    740, accuracy (SELU/ELU/RELU):  62.5% |  61.7% |  62.5%, loss (SELU/ELU/RELU): 0.91 | 1.04 | 1.14\n",
      "Global Step:    750, accuracy (SELU/ELU/RELU):  68.0% |  58.6% |  59.4%, loss (SELU/ELU/RELU): 1.02 | 1.06 | 1.23\n",
      "Global Step:    760, accuracy (SELU/ELU/RELU):  72.7% |  66.4% |  68.0%, loss (SELU/ELU/RELU): 0.80 | 0.96 | 1.00\n",
      "Global Step:    770, accuracy (SELU/ELU/RELU):  70.3% |  64.1% |  60.9%, loss (SELU/ELU/RELU): 0.90 | 1.02 | 1.11\n",
      "Global Step:    780, accuracy (SELU/ELU/RELU):  59.4% |  60.9% |  55.5%, loss (SELU/ELU/RELU): 1.09 | 1.15 | 1.23\n",
      "Global Step:    790, accuracy (SELU/ELU/RELU):  64.8% |  66.4% |  52.3%, loss (SELU/ELU/RELU): 0.94 | 1.05 | 1.29\n",
      "Global Step:    800, accuracy (SELU/ELU/RELU):  64.8% |  61.7% |  56.2%, loss (SELU/ELU/RELU): 0.91 | 1.04 | 1.17\n",
      "Accuracy on Test-Set (SELU/ELU/RELU): 60.96% | 59.29% | 56.81%\n",
      "Saved checkpoint.\n",
      "Global Step:    810, accuracy (SELU/ELU/RELU):  60.9% |  56.2% |  57.8%, loss (SELU/ELU/RELU): 1.06 | 1.11 | 1.23\n",
      "Global Step:    820, accuracy (SELU/ELU/RELU):  62.5% |  57.8% |  58.6%, loss (SELU/ELU/RELU): 1.03 | 1.11 | 1.15\n",
      "Global Step:    830, accuracy (SELU/ELU/RELU):  56.2% |  54.7% |  51.6%, loss (SELU/ELU/RELU): 1.05 | 1.17 | 1.25\n",
      "Global Step:    840, accuracy (SELU/ELU/RELU):  65.6% |  63.3% |  59.4%, loss (SELU/ELU/RELU): 0.92 | 1.02 | 1.11\n",
      "Global Step:    850, accuracy (SELU/ELU/RELU):  66.4% |  63.3% |  52.3%, loss (SELU/ELU/RELU): 0.98 | 1.02 | 1.21\n",
      "Global Step:    860, accuracy (SELU/ELU/RELU):  63.3% |  61.7% |  53.1%, loss (SELU/ELU/RELU): 0.99 | 1.12 | 1.29\n",
      "Global Step:    870, accuracy (SELU/ELU/RELU):  72.7% |  68.8% |  61.7%, loss (SELU/ELU/RELU): 0.78 | 0.91 | 1.08\n",
      "Global Step:    880, accuracy (SELU/ELU/RELU):  62.5% |  60.9% |  58.6%, loss (SELU/ELU/RELU): 1.04 | 1.15 | 1.31\n",
      "Global Step:    890, accuracy (SELU/ELU/RELU):  58.6% |  57.8% |  54.7%, loss (SELU/ELU/RELU): 1.00 | 1.15 | 1.18\n",
      "Global Step:    900, accuracy (SELU/ELU/RELU):  61.7% |  54.7% |  49.2%, loss (SELU/ELU/RELU): 1.10 | 1.17 | 1.34\n",
      "Accuracy on Test-Set (SELU/ELU/RELU): 63.74% | 61.59% | 56.13%\n",
      "Saved checkpoint.\n",
      "Global Step:    910, accuracy (SELU/ELU/RELU):  68.8% |  67.2% |  59.4%, loss (SELU/ELU/RELU): 0.92 | 0.99 | 1.11\n",
      "Global Step:    920, accuracy (SELU/ELU/RELU):  68.8% |  64.8% |  62.5%, loss (SELU/ELU/RELU): 0.85 | 0.91 | 1.00\n",
      "Global Step:    930, accuracy (SELU/ELU/RELU):  61.7% |  63.3% |  56.2%, loss (SELU/ELU/RELU): 0.99 | 0.99 | 1.09\n",
      "Global Step:    940, accuracy (SELU/ELU/RELU):  65.6% |  62.5% |  60.2%, loss (SELU/ELU/RELU): 0.95 | 1.08 | 1.17\n",
      "Global Step:    950, accuracy (SELU/ELU/RELU):  60.2% |  59.4% |  55.5%, loss (SELU/ELU/RELU): 1.09 | 1.16 | 1.21\n",
      "Global Step:    960, accuracy (SELU/ELU/RELU):  71.9% |  59.4% |  64.1%, loss (SELU/ELU/RELU): 0.88 | 1.00 | 1.03\n",
      "Global Step:    970, accuracy (SELU/ELU/RELU):  68.8% |  63.3% |  59.4%, loss (SELU/ELU/RELU): 0.96 | 1.09 | 1.21\n",
      "Global Step:    980, accuracy (SELU/ELU/RELU):  63.3% |  64.1% |  60.9%, loss (SELU/ELU/RELU): 1.07 | 1.09 | 1.15\n",
      "Global Step:    990, accuracy (SELU/ELU/RELU):  64.1% |  66.4% |  63.3%, loss (SELU/ELU/RELU): 0.88 | 0.98 | 1.03\n",
      "Global Step:   1000, accuracy (SELU/ELU/RELU):  61.7% |  57.8% |  55.5%, loss (SELU/ELU/RELU): 1.14 | 1.24 | 1.32\n",
      "Accuracy on Test-Set (SELU/ELU/RELU): 64.31% | 61.46% | 58.16%\n",
      "WARNING:tensorflow:From /home/kai/miniconda3/envs/snn/lib/python3.7/site-packages/tensorflow/python/training/saver.py:960: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "Saved checkpoint.\n",
      "Global Step:   1010, accuracy (SELU/ELU/RELU):  72.7% |  68.8% |  70.3%, loss (SELU/ELU/RELU): 0.79 | 0.88 | 0.91\n",
      "Global Step:   1020, accuracy (SELU/ELU/RELU):  63.3% |  64.8% |  54.7%, loss (SELU/ELU/RELU): 1.02 | 1.03 | 1.20\n",
      "Global Step:   1030, accuracy (SELU/ELU/RELU):  67.2% |  66.4% |  58.6%, loss (SELU/ELU/RELU): 1.04 | 1.08 | 1.21\n",
      "Global Step:   1040, accuracy (SELU/ELU/RELU):  68.0% |  66.4% |  60.2%, loss (SELU/ELU/RELU): 0.86 | 0.97 | 1.07\n",
      "Global Step:   1050, accuracy (SELU/ELU/RELU):  71.1% |  68.0% |  58.6%, loss (SELU/ELU/RELU): 0.88 | 0.96 | 1.16\n",
      "Global Step:   1060, accuracy (SELU/ELU/RELU):  64.8% |  64.1% |  62.5%, loss (SELU/ELU/RELU): 0.99 | 1.00 | 1.10\n",
      "Global Step:   1070, accuracy (SELU/ELU/RELU):  69.5% |  70.3% |  64.1%, loss (SELU/ELU/RELU): 0.86 | 0.89 | 1.07\n",
      "Global Step:   1080, accuracy (SELU/ELU/RELU):  75.8% |  68.8% |  58.6%, loss (SELU/ELU/RELU): 0.84 | 0.94 | 1.20\n",
      "Global Step:   1090, accuracy (SELU/ELU/RELU):  72.7% |  65.6% |  58.6%, loss (SELU/ELU/RELU): 0.87 | 0.99 | 1.02\n",
      "Global Step:   1100, accuracy (SELU/ELU/RELU):  70.3% |  68.0% |  55.5%, loss (SELU/ELU/RELU): 0.91 | 1.00 | 1.17\n",
      "Accuracy on Test-Set (SELU/ELU/RELU): 65.99% | 62.98% | 57.34%\n",
      "Saved checkpoint.\n",
      "Global Step:   1110, accuracy (SELU/ELU/RELU):  68.0% |  64.8% |  60.2%, loss (SELU/ELU/RELU): 0.93 | 1.03 | 1.11\n",
      "Global Step:   1120, accuracy (SELU/ELU/RELU):  63.3% |  61.7% |  64.1%, loss (SELU/ELU/RELU): 0.87 | 0.97 | 1.13\n",
      "Global Step:   1130, accuracy (SELU/ELU/RELU):  68.0% |  59.4% |  56.2%, loss (SELU/ELU/RELU): 0.93 | 1.07 | 1.20\n",
      "Global Step:   1140, accuracy (SELU/ELU/RELU):  74.2% |  68.0% |  60.2%, loss (SELU/ELU/RELU): 0.75 | 0.87 | 1.04\n",
      "Global Step:   1150, accuracy (SELU/ELU/RELU):  70.3% |  67.2% |  66.4%, loss (SELU/ELU/RELU): 0.85 | 0.94 | 0.96\n",
      "Global Step:   1160, accuracy (SELU/ELU/RELU):  71.1% |  66.4% |  62.5%, loss (SELU/ELU/RELU): 0.82 | 0.89 | 1.04\n",
      "Global Step:   1170, accuracy (SELU/ELU/RELU):  74.2% |  71.1% |  69.5%, loss (SELU/ELU/RELU): 0.84 | 0.90 | 0.97\n",
      "Global Step:   1180, accuracy (SELU/ELU/RELU):  75.0% |  73.4% |  65.6%, loss (SELU/ELU/RELU): 0.71 | 0.84 | 0.96\n",
      "Global Step:   1190, accuracy (SELU/ELU/RELU):  64.8% |  62.5% |  58.6%, loss (SELU/ELU/RELU): 0.96 | 1.06 | 1.17\n",
      "Global Step:   1200, accuracy (SELU/ELU/RELU):  71.9% |  69.5% |  64.1%, loss (SELU/ELU/RELU): 0.92 | 1.00 | 1.14\n",
      "Accuracy on Test-Set (SELU/ELU/RELU): 66.72% | 64.85% | 59.68%\n",
      "Saved checkpoint.\n",
      "Global Step:   1210, accuracy (SELU/ELU/RELU):  72.7% |  66.4% |  68.0%, loss (SELU/ELU/RELU): 0.76 | 0.89 | 0.92\n",
      "Global Step:   1220, accuracy (SELU/ELU/RELU):  66.4% |  60.9% |  64.1%, loss (SELU/ELU/RELU): 0.92 | 1.06 | 1.07\n",
      "Global Step:   1230, accuracy (SELU/ELU/RELU):  68.8% |  65.6% |  57.8%, loss (SELU/ELU/RELU): 0.94 | 1.03 | 1.16\n",
      "Global Step:   1240, accuracy (SELU/ELU/RELU):  73.4% |  67.2% |  61.7%, loss (SELU/ELU/RELU): 0.78 | 0.93 | 1.01\n",
      "Global Step:   1250, accuracy (SELU/ELU/RELU):  61.7% |  58.6% |  57.0%, loss (SELU/ELU/RELU): 0.99 | 1.08 | 1.17\n",
      "Global Step:   1260, accuracy (SELU/ELU/RELU):  69.5% |  67.2% |  62.5%, loss (SELU/ELU/RELU): 0.78 | 0.91 | 1.02\n",
      "Global Step:   1270, accuracy (SELU/ELU/RELU):  68.8% |  68.0% |  66.4%, loss (SELU/ELU/RELU): 0.78 | 0.81 | 0.93\n",
      "Global Step:   1280, accuracy (SELU/ELU/RELU):  71.9% |  70.3% |  61.7%, loss (SELU/ELU/RELU): 0.97 | 1.00 | 1.08\n",
      "Global Step:   1290, accuracy (SELU/ELU/RELU):  73.4% |  65.6% |  58.6%, loss (SELU/ELU/RELU): 0.86 | 0.94 | 1.08\n",
      "Global Step:   1300, accuracy (SELU/ELU/RELU):  69.5% |  64.8% |  57.8%, loss (SELU/ELU/RELU): 0.90 | 0.99 | 1.07\n",
      "Accuracy on Test-Set (SELU/ELU/RELU): 67.37% | 64.33% | 61.65%\n",
      "Saved checkpoint.\n",
      "Global Step:   1310, accuracy (SELU/ELU/RELU):  65.6% |  68.8% |  64.8%, loss (SELU/ELU/RELU): 0.81 | 0.99 | 1.06\n",
      "Global Step:   1320, accuracy (SELU/ELU/RELU):  72.7% |  68.0% |  65.6%, loss (SELU/ELU/RELU): 0.80 | 0.85 | 0.98\n",
      "Global Step:   1330, accuracy (SELU/ELU/RELU):  71.9% |  68.8% |  68.0%, loss (SELU/ELU/RELU): 0.80 | 0.91 | 1.02\n",
      "Global Step:   1340, accuracy (SELU/ELU/RELU):  70.3% |  71.1% |  64.1%, loss (SELU/ELU/RELU): 0.83 | 0.82 | 1.00\n",
      "Global Step:   1350, accuracy (SELU/ELU/RELU):  63.3% |  64.1% |  58.6%, loss (SELU/ELU/RELU): 1.16 | 1.10 | 1.24\n",
      "Global Step:   1360, accuracy (SELU/ELU/RELU):  70.3% |  71.1% |  66.4%, loss (SELU/ELU/RELU): 0.87 | 0.91 | 1.00\n",
      "Global Step:   1370, accuracy (SELU/ELU/RELU):  71.1% |  68.8% |  64.8%, loss (SELU/ELU/RELU): 0.77 | 0.83 | 1.00\n",
      "Global Step:   1380, accuracy (SELU/ELU/RELU):  75.0% |  70.3% |  64.8%, loss (SELU/ELU/RELU): 0.84 | 0.92 | 1.01\n",
      "Global Step:   1390, accuracy (SELU/ELU/RELU):  70.3% |  68.0% |  58.6%, loss (SELU/ELU/RELU): 0.84 | 0.94 | 1.08\n",
      "Global Step:   1400, accuracy (SELU/ELU/RELU):  71.1% |  71.9% |  67.2%, loss (SELU/ELU/RELU): 0.78 | 0.88 | 0.99\n",
      "Accuracy on Test-Set (SELU/ELU/RELU): 67.59% | 65.36% | 61.38%\n",
      "Saved checkpoint.\n",
      "Global Step:   1410, accuracy (SELU/ELU/RELU):  70.3% |  68.8% |  64.1%, loss (SELU/ELU/RELU): 0.72 | 0.80 | 0.91\n",
      "Global Step:   1420, accuracy (SELU/ELU/RELU):  76.6% |  74.2% |  72.7%, loss (SELU/ELU/RELU): 0.79 | 0.80 | 0.89\n",
      "Global Step:   1430, accuracy (SELU/ELU/RELU):  79.7% |  75.0% |  69.5%, loss (SELU/ELU/RELU): 0.68 | 0.70 | 0.82\n",
      "Global Step:   1440, accuracy (SELU/ELU/RELU):  68.0% |  65.6% |  60.9%, loss (SELU/ELU/RELU): 0.91 | 0.95 | 1.03\n",
      "Global Step:   1450, accuracy (SELU/ELU/RELU):  69.5% |  74.2% |  69.5%, loss (SELU/ELU/RELU): 0.79 | 0.86 | 0.95\n",
      "Global Step:   1460, accuracy (SELU/ELU/RELU):  74.2% |  74.2% |  66.4%, loss (SELU/ELU/RELU): 0.72 | 0.80 | 0.97\n",
      "Global Step:   1470, accuracy (SELU/ELU/RELU):  79.7% |  75.0% |  68.0%, loss (SELU/ELU/RELU): 0.68 | 0.73 | 0.87\n",
      "Global Step:   1480, accuracy (SELU/ELU/RELU):  71.1% |  73.4% |  69.5%, loss (SELU/ELU/RELU): 0.83 | 0.87 | 0.96\n",
      "Global Step:   1490, accuracy (SELU/ELU/RELU):  76.6% |  69.5% |  60.9%, loss (SELU/ELU/RELU): 0.71 | 0.88 | 1.01\n",
      "Global Step:   1500, accuracy (SELU/ELU/RELU):  71.1% |  67.2% |  66.4%, loss (SELU/ELU/RELU): 0.77 | 0.86 | 0.95\n",
      "Accuracy on Test-Set (SELU/ELU/RELU): 67.46% | 65.93% | 63.55%\n",
      "Saved checkpoint.\n",
      "Global Step:   1510, accuracy (SELU/ELU/RELU):  75.0% |  78.1% |  70.3%, loss (SELU/ELU/RELU): 0.72 | 0.74 | 0.89\n",
      "Global Step:   1520, accuracy (SELU/ELU/RELU):  68.8% |  68.8% |  57.8%, loss (SELU/ELU/RELU): 0.85 | 0.90 | 1.08\n",
      "Global Step:   1530, accuracy (SELU/ELU/RELU):  71.9% |  75.0% |  71.1%, loss (SELU/ELU/RELU): 0.81 | 0.82 | 0.91\n",
      "Global Step:   1540, accuracy (SELU/ELU/RELU):  75.8% |  69.5% |  67.2%, loss (SELU/ELU/RELU): 0.71 | 0.83 | 0.93\n",
      "Global Step:   1550, accuracy (SELU/ELU/RELU):  69.5% |  63.3% |  67.2%, loss (SELU/ELU/RELU): 0.85 | 0.94 | 1.00\n",
      "Global Step:   1560, accuracy (SELU/ELU/RELU):  68.8% |  63.3% |  57.0%, loss (SELU/ELU/RELU): 0.95 | 0.99 | 1.22\n",
      "Global Step:   1570, accuracy (SELU/ELU/RELU):  73.4% |  67.2% |  64.8%, loss (SELU/ELU/RELU): 0.77 | 0.85 | 1.03\n",
      "Global Step:   1580, accuracy (SELU/ELU/RELU):  75.8% |  71.1% |  68.8%, loss (SELU/ELU/RELU): 0.70 | 0.84 | 0.88\n",
      "Global Step:   1590, accuracy (SELU/ELU/RELU):  64.8% |  71.1% |  65.6%, loss (SELU/ELU/RELU): 0.82 | 0.86 | 0.95\n",
      "Global Step:   1600, accuracy (SELU/ELU/RELU):  74.2% |  68.0% |  60.2%, loss (SELU/ELU/RELU): 0.79 | 0.88 | 1.03\n",
      "Accuracy on Test-Set (SELU/ELU/RELU): 67.96% | 66.13% | 62.01%\n",
      "Saved checkpoint.\n",
      "Global Step:   1610, accuracy (SELU/ELU/RELU):  75.8% |  71.9% |  71.9%, loss (SELU/ELU/RELU): 0.73 | 0.78 | 0.80\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-13-6e9adb575f69>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     25\u001B[0m             \u001B[0msess\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0m_ITERATION\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtrain_x\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtrain_y\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtest_x\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtest_y\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     26\u001B[0m             \u001B[0mmodels\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m{\u001B[0m\u001B[0;34m\"relu\"\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mrelu\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"selu\"\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mselu\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"elu\"\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0melu\u001B[0m\u001B[0;34m}\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 27\u001B[0;31m             global_step=global_step)\n\u001B[0m\u001B[1;32m     28\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-9-ccc34dd45f89>\u001B[0m in \u001B[0;36mtrain\u001B[0;34m(session, num_iterations, train_x, train_y, test_x, test_y, models, global_step)\u001B[0m\n\u001B[1;32m     24\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     25\u001B[0m         \u001B[0;31m# train\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 26\u001B[0;31m         \u001B[0msession\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrun\u001B[0m\u001B[0;34m(\u001B[0m \u001B[0moptimizers\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfeed_dict\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mfeed_dict\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     27\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     28\u001B[0m         \u001B[0;31m# print training loss\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/snn/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001B[0m in \u001B[0;36mrun\u001B[0;34m(self, fetches, feed_dict, options, run_metadata)\u001B[0m\n\u001B[1;32m    948\u001B[0m     \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    949\u001B[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001B[0;32m--> 950\u001B[0;31m                          run_metadata_ptr)\n\u001B[0m\u001B[1;32m    951\u001B[0m       \u001B[0;32mif\u001B[0m \u001B[0mrun_metadata\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    952\u001B[0m         \u001B[0mproto_data\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtf_session\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mTF_GetBuffer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrun_metadata_ptr\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/snn/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001B[0m in \u001B[0;36m_run\u001B[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001B[0m\n\u001B[1;32m   1171\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mfinal_fetches\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0mfinal_targets\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mhandle\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mfeed_dict_tensor\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1172\u001B[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001B[0;32m-> 1173\u001B[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001B[0m\u001B[1;32m   1174\u001B[0m     \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1175\u001B[0m       \u001B[0mresults\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/snn/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001B[0m in \u001B[0;36m_do_run\u001B[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001B[0m\n\u001B[1;32m   1348\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mhandle\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1349\u001B[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001B[0;32m-> 1350\u001B[0;31m                            run_metadata)\n\u001B[0m\u001B[1;32m   1351\u001B[0m     \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1352\u001B[0m       \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_do_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0m_prun_fn\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mhandle\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfeeds\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfetches\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/snn/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001B[0m in \u001B[0;36m_do_call\u001B[0;34m(self, fn, *args)\u001B[0m\n\u001B[1;32m   1354\u001B[0m   \u001B[0;32mdef\u001B[0m \u001B[0m_do_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfn\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1355\u001B[0m     \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1356\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mfn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1357\u001B[0m     \u001B[0;32mexcept\u001B[0m \u001B[0merrors\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mOpError\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1358\u001B[0m       \u001B[0mmessage\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcompat\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mas_text\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmessage\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/snn/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001B[0m in \u001B[0;36m_run_fn\u001B[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001B[0m\n\u001B[1;32m   1339\u001B[0m       \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_extend_graph\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1340\u001B[0m       return self._call_tf_sessionrun(\n\u001B[0;32m-> 1341\u001B[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001B[0m\u001B[1;32m   1342\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1343\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_prun_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mhandle\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfeed_dict\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfetch_list\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/snn/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001B[0m in \u001B[0;36m_call_tf_sessionrun\u001B[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001B[0m\n\u001B[1;32m   1427\u001B[0m     return tf_session.TF_SessionRun_wrapper(\n\u001B[1;32m   1428\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_session\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moptions\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfeed_dict\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfetch_list\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtarget_list\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1429\u001B[0;31m         run_metadata)\n\u001B[0m\u001B[1;32m   1430\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1431\u001B[0m   \u001B[0;32mdef\u001B[0m \u001B[0m_call_tf_sessionprun\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mhandle\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfeed_dict\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfetch_list\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# Some Tensorflow configuration\n",
    "tf_config = tf.ConfigProto()\n",
    "tf_config.gpu_options.allow_growth = True\n",
    "\n",
    "# Initialize Dataset\n",
    "train_x, train_y, train_l = get_data_set(\"train\", cifar=10)\n",
    "test_x, test_y, test_l = get_data_set(\"test\", cifar=10)\n",
    "\n",
    "# step counter\n",
    "global_step = tf.Variable(initial_value=0, name='global_step', trainable=False)\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session(config=tf_config) as sess:\n",
    "    try:\n",
    "        print(\"Trying to restore last checkpoint ...\")\n",
    "        last_chk_path = tf.train.latest_checkpoint(checkpoint_dir=_SAVE_PATH)\n",
    "        saver.restore(sess, save_path=last_chk_path)\n",
    "        print(\"Restored checkpoint from:\", last_chk_path)\n",
    "    except:\n",
    "        print(\"Failed to restore checkpoint. Initializing variables instead.\")\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    if _ITERATION != 0:\n",
    "        train_loss, train_accuracy, test_accuracy = train(\n",
    "            sess, _ITERATION, train_x, train_y, test_x, test_y, \n",
    "            models={\"relu\": relu, \"selu\": selu, \"elu\": elu}, \n",
    "            global_step=global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Training Loss, Training Accuracy and Test Accuracy for the three activation functions\n",
    "plot(train_loss, train_accuracy, test_accuracy)        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}